<section xml:id="Sec_tVariable">
    <title>The <m>t</m>-Variable and Sampling Distribution of Numerical Variables (N1)</title>

   <introduction>
        <p> In this section, we transition away from categorical variables and begin looking at the sampling distributions of <em>numerical</em> variables.
        </p>

        <remark>
          <p>
            Recall from <xref ref="Sec_Center"/> that given a numerical variable <m>X</m> and a sample from <m>X</m> of size <m>n</m>, we can obtain a sample mean <m>\bar{x}</m>.
          </p>
          <p>
            As we know, each time we sample <m>X</m>, we obtain potentially a different <m>\bar{x}</m>, so <m>\bar{x}</m> is a random variable from a <em>sampling distribution</em>.  The random variable <m>\bar{x}</m> will play the role similar to that of <m>\hat{p}</m> in <xref ref="Chap_Categorical"/>.  We recognize <m>\bar{x}</m> as a point setimate for the true mean of <m>X</m>: <m>\mu_X</m>.
          </p>
        </remark>


        
 <exploration xml:id="exploration-AverageDieRolls">
      <title>Rolling Dice and Averaging the results.</title>

      <introduction>
          <p>
             Suppose I roll <c>dice_num</c> dice and take the average result.  Let <m>X</m> be the random variable indicating the outcome of a six-sided die.
</p>
          
      </introduction>

      <task>
        <p>
          Following <xref ref="Sec_RandomVariables"/>,find <m>E(X), Var(X), \sigma_X</m>.
        </p>
      </task>

      <task>
        <p>
          Let <m>A_2</m> be the average of two die rolls: <m>A_2=\frac{1}{2}(X_1+X_2).</m>  Using <xref ref="remark-linofEandV"/>, find <m>E(A_2), Var(A_2), \sigma_{A_2}.</m>
        </p>
      </task>

       <task>
        <p>
          Run the following code to simulate <c>trials=1000</c> trials where one rolls <c>num_dice=2</c> dice and takes the average, and display the mean and standard deviation of these outcomes:

          <sage language="r">
          <input>
          trials=1000
          num_dice=2

          averageroll=rep(NA, trials)

          for(i in 1:trials){
            averageroll[i]=sum(sample(c(1,2,3,4,5,6), num_dice, replace=TRUE))/num_dice
          }
          hist(averageroll, breaks=25, prob=TRUE)
          print(mean(averageroll))
          print(sd(averageroll))
          </input>
          </sage>
          How do these values compare to what you found in (b)?
        </p>
      </task>

      <task>
        <p>
          Let <m>A_3</m> be the average of two die rolls: <m>A_2=\frac{1}{3}(X_1+X_2+X_3).</m>  Using <xref ref="remark-linofEandV"/>, find <m>E(A_3), Var(A_3), \sigma_{A_3}.</m>
        </p>
      </task>

      <task>
        <p>
          Re-run the code in (c) with <c>num_dice=3</c>, how do those values compare to what you found in (d)?
        </p>
      </task>

      <task>
        <p>
          Re-run the code in (c) with <c>num_dice=30</c>, <c>num_dice=50</c>, <c>num_dice=100</c> What do we notice about the <c>mean</c> and <c>sd</c> as <c>num_dice</c> increases?  How does the shape of the graph change?
        </p>
      </task>


      


</exploration>

        
    </introduction>


    <subsection>
      <title><m>t</m>-Variables</title>
      <p>
      As we saw in <xref ref="exploration-AverageDieRolls"/>, we saw a phonomena very similar to what we saw in <xref ref="theorem-CLTprop"/>.  In <xref ref="theorem-CLTprop"/>, the sampling distribution for <m>\hat{p}</m> was approximately normal.  We have a similar result for the sampling distribution for <m>\bar{x}</m>.
    </p>


      <theorem xml:id="theorem-CLTnum">
              <title>The Central Limit Theorem (Numerical)</title>
              <p>
                Let <m>X</m> be a numerical variable with true mean <m>\mu</m> and standard deviation <m>\sigma</m>.  Then for a sufficiently large sample (typically <m>\geq 30</m>) the sampling distribution of <m>\bar{m}</m> is approximately <em>normally distributed</em> with pararmeters <me>\mu_{\bar{x}}=\mu,\ \ \  SE_{\bar{m}}=\frac{\sigma}{\sqrt{n}}.</me>
              </p>

            </theorem>


    <remark>
      <p>
        We can see how the average die rolls of <xref ref="exploration-AverageDieRolls"/> follow this.  Run the following code to plot the histogram from <xref ref="exploration-AverageDieRolls"/>, along with a normal curve with parameters mean <c>mu=3.5</c> and standard deviation <c>SE=sqrt(35/12)/sqrt(num_dice)</c>:

        <sage language="r">
          <input>
          trials=1000
          num_dice=30

          mu=3.5
          SE=sqrt(35/12)/sqrt(num_dice)

          averageroll=rep(NA, trials)

          for(i in 1:trials){
            averageroll[i]=sum(sample(c(1,2,3,4,5,6), num_dice, replace=TRUE))/num_dice
          }
          hist(averageroll, breaks=25, prob=TRUE)
          curve(dnorm(x, mean=mu, sd=SE), col="darkblue", lwd=2, add=TRUE, yaxt="n")
          print(mean(averageroll))
          print(sd(averageroll))
          </input>
          </sage>
          Edit <c>num_dice</c> and see how the curve matches the histogram.
        </p>
      </remark>


      <activity xml:id="activity-stdisRV">
          <title>Variation in Parameters</title>
          <introduction>
              <p>With categorical variables, the mean and standard deviation of the sampling distribution is totally determined by one parameter: <m>p</m>.  We can see this in the statement of <xref ref="theorem-CLTprop"/>.  So when we assume a null hypothesis and set <m>p=p_0</m>, this strictly determines the hypothetical sampling distribution.</p>

              <p>
                As we see in <xref ref="theorem-CLTnum"/>, the sampling distribution for <m>\bar{x}</m> is determined by both <m>\mu</m> <em>and</em> <m>\sigma</m>.  So if one were to conduct a hypothesis test and set <m>\mu=\mu_0</m>, there's still the question of what <m>\sigma</m> is.  The general practice is to assume it's the same as the sample standard deviation, but how good of an estimate is this?
              </p>

              <p>
                Run the following code to download and the <c>ames.csv</c> data set which contains information of houses in Ames, Iowa, and to see it's variable names:

                <sage language="r">
                <input>
                ames = read.csv("https://github.com/TienChih/tbil-stats/raw/main/data/ames.csv")
                
                names(ames)
                </input>
                </sage>

                Click here to learn more about this data set: <url href="https://www.openintro.org/data/index.php?data=ames"/>.

              </p>

              
          </introduction>

          <task>
            <p>
              Run the following code to sample 30 random houses from Ames, Iowa and display their housing prices:
              <sage language="r">
              <input>
              n=30
              index = sample(1:nrow(ames), n)
              samp=ames[index,]
              samp$price
              </input>
              </sage>
            </p>
          </task>

          <task>
            <p>
              Run the following code to show the standard deviation of  housing prices in this sample:
              <sage language="r">
              <input>
              sd(samp$price)
              </input>
              </sage>
            </p>
          </task>

          <task>
            <p>
              Run the following code to sample 30 new random houses from Ames, Iowa and display the standard deviation of their housing prices:
              <sage language="r">
              <input>
              n=30
              index = sample(1:nrow(ames), n)
              samp=ames[index,]
              sd(samp$price)
              </input>
              </sage>
              How does this outcome compare to what you found in (a)?
            </p>
          </task>

          <task>
            <p>
              Run the following code to, for <c>trials=1000</c> times, sample 30 new random houses from Ames, Iowa and record the standard deviation of their housing prices, and display a histogram of the standard deviations:
              <sage language="r">
              <input>
              n=30
              trials=1000
              sdvec=rep(NA, trials)

              for(i in 1:trials){
                index = sample(1:nrow(ames), n)
                samp=ames[index,]
                sdvec[i]=sd(samp$price)  
              }

              hist(sdvec, breaks=25)
              </input>
              </sage>
              What do we notice about the possible variation in sample standard deviations?
            </p>
          </task>


          <task>
            <p>
              Run the following code to redisplay the above histogram, along with the actual standard deviation of housing prices in Ames, Iowa:
              <sage language="r">
              <input>
              hist(sdvec, breaks=25)
              abline(v = sd(ames$price), col="red", lwd=3, lty=2)
              </input>
              </sage>
              What do we notice about the possible variation in sample standard deviations?
            </p>
          </task>

          <task>
            <p>
              To see how much variation there could be in sampling distributions, run the following code to plot a normal curve for each sample standard deviation we found, each curve has mean 0, but standard deviation equal to one we found in our above simulation:
              <sage language="r">
              <input>
              values = seq(-300000, 300000, length=100)

              plot(values, dnorm(values, mean=0, sd=sdvec[1]), type="l", lty=2)

              for (i in 2:trials){
                lines(values, dnorm(values, mean=0, sd=sdvec[i])) 
              }
              </input>
              </sage>
              How much variation is there between curves, even with the same means?
            </p>
          </task>

           <task>
            <p>
              Run the following code to, for <c>trials=1000</c> times, sample now <c>n=500</c> new random houses from Ames, Iowa and record the standard deviation of their housing prices, and display a histogram of the standard deviations:
              <sage language="r">
              <input>
              n=500
              trials=1000
              sdvec500=rep(NA, trials)

              for(i in 1:trials){
                index = sample(1:nrow(ames), n)
                samp=ames[index,]
                sdvec500[i]=sd(samp$price)  
              }

              hist(sdvec500, breaks=25)
              abline(v = sd(ames$price), col="red", lwd=3, lty=2)
              </input>
              </sage>
              What do we notice about the possible variation in sample standard deviations compared to what we saw in (d)?
            </p>
          </task>



      </activity>

    </subsection>

    <subsection>
      <title>The <m>t</m>-distribution</title>


  <definition xml:id="definition-tcurve">
    <title><m>t</m>-Random Variable</title>
      <p>
        Looking at <xref ref="activity-stdisRV"/>, we notice:
        <ul>
          <li>A normal curve where we use a sample standard deviation <m>s</m> in lieu of <m>\sigma</m> may be highly inaccurate, since there is a lot of variation of what <m>s</m> is in comparison to <m>\sigma</m>.</li>
          <li>This variation decreases as we increase <m>n</m> the size of the sample.</li>
        </ul>
        
        To account for this, we introduce what we call the standard <m>t</m>-distribution (mean 0, standard deviation 1).  The technical formula for a <m>t</m>-distribution is uninteresting and tedious.    The main thing we want to understand about the standard <m>t</m>-distribution with mean <m>0</m> and standard deviation 1, is that it has an additional parameter: <em>degrees of freedom</em>: <m>d_f</m>.   For a <m>t</m>-distribution, the number of degrees of freedom is <m>d_f=n-1</m> where <m>n</m> is the sample size.
      </p>

      <p>
        We notice that when <m>d_f</m> is small, the <m>t</m>-distribution resembles a much widened normal distribution to account for the variability in the sample standard deviation.  As <m>d_f</m> increases, the <m>t</m>-distribution grows to resemble a normal distribution.
        <interactive desmos="mb9tb158tl"/>
      </p>
    </definition>

    <activity xml:id="activity-tprobabilities">
        <title>Probabilities and the <m>t</m>-Distribution</title>
        <introduction>
             <p>Probabilities of <m>t</m> variables are computed in a manner similar to that of normal variables, via areas as in <xref ref="activity-standardnormprob"/>. </p>
            
           <p>
              Below, we can see that for a <m>t</m> variable with 8 degrees of freedom, the probability that <m>t</m> is less than <m>-0.7</m> is <m>P(t_8\lt -0.7)\approx 0.2519.</m>
              <interactive desmos="7q6z4qkfmu"/>
            </p>
            <p>
              We can also confirm this by running the following:
              <sage language="r">
              <input>
              pt(-.7, df=8, lower.tail=TRUE)
              </input>
              </sage>
            </p>
        </introduction>
    

    <task>
      <p>
        For a <m>t</m>-variable with 19 degrees of freedom, compute the probability <m>t</m> is greater than 1.1: <m>P(t_{19}>1.1)</m>.
      </p>
    </task>

    <task>
      <p>
        For a <m>t</m>-variable with 100 degrees of freedom, compute the probability <m>t</m> is between -2 and 1.5: <m>P(-2\lt t_{100}\lt1.5)</m>.
      </p>
    </task>

    <task>
      <p>
        For <m>t</m> variables with degrees of freedom 5, 20 and 200, compute <m>P(-1\lt t\lt1)</m>.  What do we notice as the degrees of freedom increase?
      </p>
    </task>

    <task>
      <p>
        For <m>t</m> variables with degrees of freedom 5, 20 and 200, compute <m>P(t>2)</m>.  What do we notice as the degrees of freedom increase?
      </p>
    </task>
    </activity>



    <activity xml:id="activity-tprobabilitiesinverses">
        <title>Probabilities and the <m>t</m>-Distribution: Inverses</title>
        <introduction>
             <p>Just as for normal variables (see: <xref ref="activity-standardnormprobinv"/>), given an area or probability, we should be able to recover bounds for it. </p>
            
           <p>
              Below, we can see that for a <m>t</m> variable with 13 degrees of freedom, if we wanted to find a vlaue <m>t_{13}^*</m> so the probability that <m>t</m> is less than <m>t_{13}^*</m> is 70%, or <m>P(t_{13}\lt t_{13}^*)=0.7</m>, we can see that the value is about <m>t_{13}^*\approx 0.5375</m>.
              <interactive desmos="9yd3vbkaar"/>
            </p>
            <p>
              We can also confirm this by running the following:
              <sage language="r">
              <input>
              qt(0.7, df=13, lower.tail=TRUE)
              </input>
              </sage>
            </p>
        </introduction>
    

    <task>
      <p>
        For a <m>t</m>-variable with 13 degrees of freedom, find <m>t_{13}^*</m> such that <m>P(t_{13}>t_{13}^*)=0.45</m>.
      </p>
    </task>

    <task>
      <p>
        For a <m>t</m>-variable with 45 degrees of freedom, find <m>t_{45}^*</m> such that <m>P(t_{45}\lt t_{45}^*)=0.55</m>.
      </p>
    </task>

    <task>
      <p>
        For <m>t</m> variables with degrees of freedom 5, 20 and 200, find find <m>t^*</m> such that <m>P(-t^*\lt t\lt t^*)=0.85</m>.  What do we notice as the degrees of freedom increase?
      </p>
    </task>
  </activity>


  <activity xml:id="activity-tscore">
        <title><m>t</m>-score for Sampling Distribution Variables</title>
        <introduction>
             <p>Just as for general normal variables, most sampling distributions do not have mean 0 and standard deviation 1. Just as with general normal variables, we each value of the sampling distribution has a corresponding <em><m>t</m>-score</em> on our general <m>t</m>-distribution . </p>
            
           <p>
              Consider a sampling distribution with mean <m>\mu</m> and standard deviation <m>SE</m>.  For each value <m>X</m> from this distribution, we can compute the <m>t</m>-score for <m>X</m> via:  <me>t=\frac{X-\mu}{SE}</me> as in <xref ref="definition-zscore"/>.
            </p>
        </introduction>
    

    <task>
      <p>
        For a sampling distribution with mean <m>\mu=45</m>, standard error <m>SE=12</m>  find the <m>t</m>-score of <m>X=60</m>.
      </p>
    </task>

    <task>
      <p>
        For a sampling distribution with mean <m>\mu=120</m>, standard error <m>SE=26</m>  find the <m>X</m> values for the <m>t</m>-scores: -1.97, 1.97.
      </p>
    </task>
  </activity>


  <activity xml:id="activity-tcomp">
        <title>Putting it Together</title>
        <introduction>
             <p>Suppose you sampled a numerical variable 20 times, and obtained the following values:
             <me>20, 36, 23, 38, 42, 29, 47, 23, 30, 37,</me> <me>45, 44, 34, 19, 31, 30, 14, 48, 50, 18.</me> 
            </p>
        </introduction>
    

    <task>
      <p>
        Compute the sample mean <m>\bar{x}</m>, and the standard deviation <m>s</m>, for the above sample.
      </p>
    </task>

    <task>
      <p>
        What is <m>n</m> the size of the sample?  Use <xref ref="theorem-CLTnum"/> to compute the standard error for the sampling distribution: <m>SE</m>.
      </p>
    </task>

    <task>
      <p>
        Use <xref ref="definition-tcurve"/> to compute the degrees of freedom of the sampling distribution.
      </p>
    </task>

    <task>
      <p>
        If we assume the sampling distribution has mean <m>\mu=30</m>, use this mean and <m>SE</m> to compute a <m>t</m>-score for <m>\bar{x}</m>, <m>t_{\bar{x}}</m>.
      </p>
    </task>

    <task>
      <p>
        Compute <m>P(t>t_{\bar{x}})</m>.
      </p>
    </task>
  </activity>





    </subsection>  


</section>
